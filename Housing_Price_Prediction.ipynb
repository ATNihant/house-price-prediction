{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üè† House Price Prediction Using Machine Learning\n",
        "\n",
        "Welcome to my first complete machine learning project!  \n",
        "In this notebook, I aim to predict house prices based on various features from the Ames Housing Dataset using regression models.\n",
        "\n",
        "This project is part of my learning journey through Kaggle's **Intro to Machine Learning** course.  \n",
        "The goal is to build a model that accurately estimates the value of a house given its attributes.\n"
      ],
      "metadata": {
        "id": "lj0tC_bQbtdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÇ Dataset Overview\n",
        "\n",
        "We'll be working with the **Ames Housing Dataset**, a well-known dataset for regression tasks.  \n",
        "It contains 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa.\n",
        "\n",
        "\n",
        "Let's start by importing the necessary libraries."
      ],
      "metadata": {
        "id": "-czSj-V0caXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
      ],
      "metadata": {
        "id": "EjN5ms_qccLh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Loading the Data\n",
        "\n",
        "We'll load the training and test datasets provided by Kaggle.  \n",
        "These contain information about houses and the target variable: `SalePrice`.\n",
        "\n",
        "Let's take a quick look at the shape and some rows of the dataset.\n"
      ],
      "metadata": {
        "id": "35tcVw7fdUTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your kaggle.json API key\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Set up Kaggle API credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the House Prices dataset\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -q house-prices-advanced-regression-techniques.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "jtyV9z_wdjMR",
        "outputId": "d9e6ffae-afcb-4000-d89c-9b57f1d8cfc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4f26fae-2145-4d16-9d68-f1be637c4aa2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d4f26fae-2145-4d16-9d68-f1be637c4aa2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "Downloading house-prices-advanced-regression-techniques.zip to /content\n",
            "  0% 0.00/199k [00:00<?, ?B/s]\n",
            "100% 199k/199k [00:00<00:00, 425MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßπ Data Cleaning & Feature Selection\n",
        "\n",
        "To keep things simple and focus on model performance, we'll:\n",
        "- Drop rows with missing target values\n",
        "- Select only numerical predictors\n",
        "- Remove columns with missing values in the training data\n"
      ],
      "metadata": {
        "id": "HiYJwScyd0ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Drop rows where target is missing\n",
        "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
        "\n",
        "# Separate target from predictors\n",
        "y = train_data.SalePrice\n",
        "X_full = train_data.drop(['SalePrice'], axis=1)\n",
        "X_test_full = test_data.copy()\n",
        "\n",
        "# Select only numerical predictors\n",
        "numerical_cols = [cname for cname in X_full.columns if\n",
        "                  X_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep only numerical columns\n",
        "X = X_full[numerical_cols].copy()\n",
        "X_test = X_test_full[numerical_cols].copy()\n",
        "\n",
        "# Drop columns with missing values (just to simplify)\n",
        "cols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n",
        "X.drop(cols_with_missing, axis=1, inplace=True)\n",
        "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
        "\n",
        "# Final shape\n",
        "print(\"Final training data shape:\", X.shape)\n",
        "print(\"Final test data shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGPJCgWfd3PD",
        "outputId": "4b6d3c63-77af-44d2-9a86-3bafc42373eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training data shape: (1460, 34)\n",
            "Final test data shape: (1459, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÇ Train-Test Split & Model Training\n",
        "\n",
        "We'll split the training data into training and validation sets to evaluate our model‚Äôs performance before testing on unseen data.\n",
        "\n",
        "Then, we'll train a Random Forest Regressor ‚Äî a robust model that often performs well with minimal tuning.\n"
      ],
      "metadata": {
        "id": "i0SsnI4of-Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation subsets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
        "                                                      train_size=0.8,\n",
        "                                                      test_size=0.2,\n",
        "                                                      random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "preds = model.predict(X_valid)\n",
        "\n",
        "# Evaluate with Mean Absolute Error\n",
        "mae = mean_absolute_error(y_valid, preds)\n",
        "print(f\"Validation MAE: {mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owsa5hRjgBD6",
        "outputId": "1cdedf56-f4b4-4cbd-c837-56e0d21e526e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAE: 18178.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Final Predictions & Conclusion\n",
        "\n",
        "With the trained model, we'll predict house prices on the test set.  \n",
        "This simulates how the model would perform on new, unseen data.\n",
        "\n",
        "Finally, I‚Äôll summarize key learnings and possible improvements.\n"
      ],
      "metadata": {
        "id": "kB38j3ZbgRb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict house prices for test data\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "# Prepare submission file (if you want to submit to Kaggle)\n",
        "output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_preds})\n",
        "output.to_csv('house_price_predictions.csv', index=False)\n",
        "\n",
        "print(\"Prediction file created: house_price_predictions.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HRbdrewgTyK",
        "outputId": "31b2b83e-eab6-439f-b5f9-39d222d050cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction file created: house_price_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Learnings:\n",
        "- Data cleaning and feature selection are crucial for model accuracy.\n",
        "- Random Forest is a powerful baseline model for regression problems.\n",
        "- Evaluating on a validation set helps avoid overfitting.\n",
        "- There‚Äôs always room to explore feature engineering, hyperparameter tuning, and trying other models.\n",
        "\n",
        "Thanks for following along! Looking forward to applying these techniques on more datasets."
      ],
      "metadata": {
        "id": "fMeaBbX7gkXj"
      }
    }
  ]
}
